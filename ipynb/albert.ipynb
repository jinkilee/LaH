{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference\n",
    "- https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_albert.py\n",
    "- https://github.com/google-research/ALBERT/blob/master/modeling.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_params(model):\n",
    "    n_params = 0\n",
    "    for param in model.parameters():\n",
    "        param_shape = list(param.shape)\n",
    "        n_params += reduce(lambda x, y: x*y, param_shape)\n",
    "    return n_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### input/output embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b534b97bf91404d9eea5e3f4fcb6a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760289.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f6fb6b4b164b0491152574a14251da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=535.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110ca34f893a453788cf1136cf217981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=71509304.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AlbertModel, AlbertTokenizer\n",
    "import torch\n",
    "\n",
    "model_nm = 'albert-large-v1'\n",
    "tokenizer = AlbertTokenizer.from_pretrained(model_nm)\n",
    "model = AlbertModel.from_pretrained(model_nm)\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(input_ids)\n",
    "last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 1024])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 128])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_output = model.embeddings(input_ids)\n",
    "emb_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = torch.ones(input_ids.shape)\n",
    "extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "extended_attention_mask = extended_attention_mask.to(dtype=torch.float32)  # fp16 compatibility\n",
    "extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_layers = model.encoder.config.num_hidden_layers\n",
    "n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_mask = [None] * n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = model.encoder(emb_output, extended_attention_mask, head_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 1024]), tensor(-154.9911, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[0].shape, trans[0].sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# AlbertTransformer's forward method\n",
    "def forward(self, hidden_states, attention_mask=None, head_mask=None):\n",
    "    hidden_states = self.embedding_hidden_mapping_in(hidden_states)\n",
    "\n",
    "    all_attentions = ()\n",
    "\n",
    "    if self.output_hidden_states:\n",
    "        all_hidden_states = (hidden_states,)\n",
    "\n",
    "    for i in range(self.config.num_hidden_layers):\n",
    "        # Number of layers in a hidden group\n",
    "        layers_per_group = int(self.config.num_hidden_layers / self.config.num_hidden_groups)\n",
    "\n",
    "        # Index of the hidden group\n",
    "        group_idx = int(i / (self.config.num_hidden_layers / self.config.num_hidden_groups))\n",
    "\n",
    "        layer_group_output = self.albert_layer_groups[group_idx](\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            head_mask[group_idx * layers_per_group : (group_idx + 1) * layers_per_group],\n",
    "        )\n",
    "        hidden_states = layer_group_output[0]\n",
    "\n",
    "        if self.output_attentions:\n",
    "            all_attentions = all_attentions + layer_group_output[-1]\n",
    "\n",
    "        if self.output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(39.1129, grad_fn=<DistBackward>)\n",
      "1 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(20.0344, grad_fn=<DistBackward>)\n",
      "2 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(16.1824, grad_fn=<DistBackward>)\n",
      "3 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(12.3042, grad_fn=<DistBackward>)\n",
      "4 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(9.8303, grad_fn=<DistBackward>)\n",
      "5 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(7.6768, grad_fn=<DistBackward>)\n",
      "6 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(6.3892, grad_fn=<DistBackward>)\n",
      "7 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(5.5773, grad_fn=<DistBackward>)\n",
      "8 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(5.1350, grad_fn=<DistBackward>)\n",
      "9 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(4.7566, grad_fn=<DistBackward>)\n",
      "10 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(4.5074, grad_fn=<DistBackward>)\n",
      "11 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(4.4292, grad_fn=<DistBackward>)\n",
      "12 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(4.4068, grad_fn=<DistBackward>)\n",
      "13 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(4.3860, grad_fn=<DistBackward>)\n",
      "14 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(4.3405, grad_fn=<DistBackward>)\n",
      "15 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(4.2796, grad_fn=<DistBackward>)\n",
      "16 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(4.3363, grad_fn=<DistBackward>)\n",
      "17 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(4.4994, grad_fn=<DistBackward>)\n",
      "18 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(4.8434, grad_fn=<DistBackward>)\n",
      "19 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(5.4376, grad_fn=<DistBackward>)\n",
      "20 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(6.2162, grad_fn=<DistBackward>)\n",
      "21 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(7.0187, grad_fn=<DistBackward>)\n",
      "22 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(7.5306, grad_fn=<DistBackward>)\n",
      "23 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(7.4768, grad_fn=<DistBackward>)\n"
     ]
    }
   ],
   "source": [
    "hidden_states = model.encoder.embedding_hidden_mapping_in(emb_output)\n",
    "dist = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "distance_list = []\n",
    "for i in range(n_layers):\n",
    "    input_embedding = hidden_states#.view(-1, 8*768)\n",
    "    layer_out = model.encoder.albert_layer_groups[0](\n",
    "        hidden_states,\n",
    "        extended_attention_mask,\n",
    "        head_mask[0*n_layers:(0+1)*n_layers]\n",
    "    )\n",
    "    hidden_states = layer_out[0]\n",
    "    output_embedding = hidden_states#.view(-1, 8*768)\n",
    "    \n",
    "    distance = torch.dist(input_embedding, output_embedding, p=2)\n",
    "    print(i, hidden_states.shape, input_embedding.shape, output_embedding.shape, distance)\n",
    "    distance_list.append(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(distance_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17683968"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### can ALBERT do NSP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/anything/git/ALBERT/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-848d3136c195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow as tf\n",
    "import modeling\n",
    "import numpy as np\n",
    "import random\n",
    "import modeling\n",
    "\n",
    "from tokenization import FullTokenizer\n",
    "from load_dataset import create_training_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nm = 'albert_large'\n",
    "model_nm = 'albert_xxlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = '/anything/git/ALBERT/models/{}/30k-clean.vocab'.format(model_nm)\n",
    "tokenizer = FullTokenizer(vocab_file=vocab_file)\n",
    "\n",
    "spm_file = '/anything/git/ALBERT/models/{}/30k-clean.model'.format(model_nm)\n",
    "tokenizer = FullTokenizer(vocab_file=None, spm_model_file=spm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = modeling.AlbertConfig.from_json_file('/anything/git/ALBERT/models/{}/albert_config.json'.format(model_nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = config.max_position_embeddings\n",
    "dupe_factor = 40\n",
    "short_seq_prob = 0.1\n",
    "masked_lm_prob = 0.15\n",
    "max_predictions_per_seq = 20\n",
    "rng = random.Random(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOP label should be 0\n",
    "sent_1 = 'How old are you?'\n",
    "sent_2 = 'I am 35 years old'\n",
    "\n",
    "# SOP label should be 1\n",
    "sent_1 = 'How old are you?'\n",
    "sent_2 = 'The Eiffel Tower is in Paris'\n",
    "\n",
    "# SOP label should be 0\n",
    "# sent_1 = 'is Obama the president of the US?'\n",
    "# sent_2 = 'No but he was'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right order\n",
    "tokens_1 = tokenizer.tokenize(sent_1)\n",
    "tokens_2 = tokenizer.tokenize(sent_2)\n",
    "tokens = ['[CLS]'] + tokens_1 + ['[SEP]'] + tokens_2 + ['[SEP]']\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "segment_ids = [0] * (len(tokens_1) + 2) + [1] * (len(tokens_2) + 1)\n",
    "token_type_ids = [1] * len(segment_ids)\n",
    "label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse order\n",
    "tokens_1 = tokenizer.tokenize(sent_1)\n",
    "tokens_2 = tokenizer.tokenize(sent_2)\n",
    "tokens = ['[CLS]'] + tokens_2 + ['[SEP]'] + tokens_1 + ['[SEP]']\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "segment_ids = [0] * (len(tokens_2) + 2) + [1] * (len(tokens_1) + 1)\n",
    "token_type_ids = [1] * len(segment_ids)\n",
    "label = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 13, 1, 3581, 315, 50, 42, 60, 3, 13, 1, 438, 13, 1, 6021, 532, 13, 1, 3581, 106, 25, 19, 13, 1, 14688, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(input_ids)\n",
    "print(segment_ids)\n",
    "print(token_type_ids)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already been converted from strings into ids\n",
    "input_ids = tf.constant([input_ids])\n",
    "segment_ids = tf.constant([segment_ids])\n",
    "token_type_ids = tf.constant([token_type_ids])\n",
    "input_label = tf.constant([label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 26, 64) (1, 64, 26, 64)\n",
      "(1, 64, 26, 64) (1, 64, 26, 64)\n",
      "(1, 64, 26, 64) (1, 64, 26, 64)\n",
      "(1, 64, 26, 64) (1, 64, 26, 64)\n",
      "(1, 64, 26, 64) (1, 64, 26, 64)\n",
      "(1, 64, 26, 64) (1, 64, 26, 64)\n",
      "(1, 64, 26, 64) (1, 64, 26, 64)\n",
      "(1, 64, 26, 64) (1, 64, 26, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0202 13:35:22.587784 139701824845568 deprecation.py:323] From /anything/git/ALBERT/modeling.py:253: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "W0202 13:35:22.589021 139701824845568 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 26, 64) (1, 64, 26, 64)\n",
      "(1, 64, 26, 64) (1, 64, 26, 64)\n",
      "(1, 64, 26, 64) (1, 64, 26, 64)\n",
      "(1, 64, 26, 64) (1, 64, 26, 64)\n"
     ]
    }
   ],
   "source": [
    "model = modeling.AlbertModel(config=config, is_training=False,\n",
    "  input_ids=input_ids, input_mask=token_type_ids, token_type_ids=token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_order_output(albert_config, input_tensor, labels):\n",
    "    with tf.variable_scope(\"cls/seq_relationship\"):\n",
    "        output_weights = tf.get_variable(\n",
    "            \"output_weights\",\n",
    "            shape=[2, albert_config.hidden_size],\n",
    "            initializer=modeling.create_initializer(\n",
    "                albert_config.initializer_range))\n",
    "        output_bias = tf.get_variable(\n",
    "            \"output_bias\", shape=[2], initializer=tf.zeros_initializer())\n",
    "        logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "        labels = tf.reshape(labels, [-1])\n",
    "        one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n",
    "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "        return (loss, per_example_loss, log_probs, output_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sentence_order_loss, sentence_order_example_loss, sentence_order_log_probs, out_weight) = get_sentence_order_output(config, model.get_pooled_output(), input_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30321643 (1, 2) [[-0.30321643 -1.3410888 ]] [[0.73843926 0.26156074]]\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    saver.restore(sess, '/anything/git/ALBERT/models/{}/model.ckpt-best'.format(model_nm))\n",
    "    \n",
    "    sop_loss, sop_prob, ow = sess.run([sentence_order_loss, sentence_order_log_probs, out_weight])\n",
    "    pred = 0 if sop_prob[0][0] > sop_prob[0][1] else 1\n",
    "    print(sop_loss, sop_prob.shape, sop_prob, np.exp(sop_prob))\n",
    "    print(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "albert_ipynb",
   "language": "python",
   "name": "env_bert-like"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
