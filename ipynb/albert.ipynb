{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference\n",
    "- https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_albert.py\n",
    "- https://github.com/google-research/ALBERT/blob/master/modeling.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_params(model):\n",
    "    n_params = 0\n",
    "    for param in model.parameters():\n",
    "        param_shape = list(param.shape)\n",
    "        n_params += reduce(lambda x, y: x*y, param_shape)\n",
    "    return n_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### input/output embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0202 13:31:17.068492 139694552987392 file_utils.py:38] PyTorch version 1.1.0 available.\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "I0202 13:31:19.300231 139694552987392 tokenization_utils.py:418] loading file https://s3.amazonaws.com/models.huggingface.co/bert/albert-large-spiece.model from cache at /root/.cache/torch/transformers/66f081790a7cd178fa9a63002d945aaed2d289c5fc14cb2fb1db322009485aaf.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf\n",
      "I0202 13:31:20.189369 139694552987392 configuration_utils.py:233] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/albert-large-config.json from cache at /root/.cache/torch/transformers/a82c2c506ba12688420ce135fa48c03861b977b25b51839a5ad8942cb5f00eb2.2454016b776a9e427e8b7dc5c04899c2593cf28a134d776293af07968d14c37e\n",
      "I0202 13:31:20.190487 139694552987392 configuration_utils.py:256] Model config AlbertConfig {\n",
      "  \"architectures\": [\n",
      "    \"AlbertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"do_sample\": false,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"finetuning_task\": null,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "I0202 13:31:21.081874 139694552987392 modeling_utils.py:440] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/albert-large-pytorch_model.bin from cache at /root/.cache/torch/transformers/05be68f9f3dfa693c90b4bd657e8ff7bc1ba6c709185b87862ac83dc0ed00c58.a2e503f03a19deb256cbf1d3284a638d77215ec1c890e77d70705d7b177b70c3\n"
     ]
    }
   ],
   "source": [
    "from transformers import AlbertModel, AlbertTokenizer\n",
    "import torch\n",
    "\n",
    "model_nm = 'albert-large-v1'\n",
    "tokenizer = AlbertTokenizer.from_pretrained(model_nm)\n",
    "model = AlbertModel.from_pretrained(model_nm)\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(input_ids)\n",
    "last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 1024])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 128])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_output = model.embeddings(input_ids)\n",
    "emb_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = torch.ones(input_ids.shape)\n",
    "extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "extended_attention_mask = extended_attention_mask.to(dtype=torch.float32)  # fp16 compatibility\n",
    "extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_layers = model.encoder.config.num_hidden_layers\n",
    "n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_mask = [None] * n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = model.encoder(emb_output, extended_attention_mask, head_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 1024]), tensor(-154.9911, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[0].shape, trans[0].sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# AlbertTransformer's forward method\n",
    "def forward(self, hidden_states, attention_mask=None, head_mask=None):\n",
    "    hidden_states = self.embedding_hidden_mapping_in(hidden_states)\n",
    "\n",
    "    all_attentions = ()\n",
    "\n",
    "    if self.output_hidden_states:\n",
    "        all_hidden_states = (hidden_states,)\n",
    "\n",
    "    for i in range(self.config.num_hidden_layers):\n",
    "        # Number of layers in a hidden group\n",
    "        layers_per_group = int(self.config.num_hidden_layers / self.config.num_hidden_groups)\n",
    "\n",
    "        # Index of the hidden group\n",
    "        group_idx = int(i / (self.config.num_hidden_layers / self.config.num_hidden_groups))\n",
    "\n",
    "        layer_group_output = self.albert_layer_groups[group_idx](\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            head_mask[group_idx * layers_per_group : (group_idx + 1) * layers_per_group],\n",
    "        )\n",
    "        hidden_states = layer_group_output[0]\n",
    "\n",
    "        if self.output_attentions:\n",
    "            all_attentions = all_attentions + layer_group_output[-1]\n",
    "\n",
    "        if self.output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(39.1129, grad_fn=<DistBackward>)\n",
      "1 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(20.0344, grad_fn=<DistBackward>)\n",
      "2 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(16.1824, grad_fn=<DistBackward>)\n",
      "3 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(12.3042, grad_fn=<DistBackward>)\n",
      "4 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(9.8303, grad_fn=<DistBackward>)\n",
      "5 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(7.6768, grad_fn=<DistBackward>)\n",
      "6 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(6.3892, grad_fn=<DistBackward>)\n",
      "7 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(5.5773, grad_fn=<DistBackward>)\n",
      "8 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(5.1350, grad_fn=<DistBackward>)\n",
      "9 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(4.7566, grad_fn=<DistBackward>)\n",
      "10 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(4.5074, grad_fn=<DistBackward>)\n",
      "11 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(4.4292, grad_fn=<DistBackward>)\n",
      "12 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(4.4068, grad_fn=<DistBackward>)\n",
      "13 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(4.3860, grad_fn=<DistBackward>)\n",
      "14 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(4.3405, grad_fn=<DistBackward>)\n",
      "15 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(4.2796, grad_fn=<DistBackward>)\n",
      "16 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(4.3363, grad_fn=<DistBackward>)\n",
      "17 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(4.4994, grad_fn=<DistBackward>)\n",
      "18 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(4.8434, grad_fn=<DistBackward>)\n",
      "19 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(5.4376, grad_fn=<DistBackward>)\n",
      "20 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(6.2162, grad_fn=<DistBackward>)\n",
      "21 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(7.0187, grad_fn=<DistBackward>)\n",
      "22 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(7.5306, grad_fn=<DistBackward>)\n",
      "23 torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) torch.Size([1, 8, 1024]) tensor(7.4768, grad_fn=<DistBackward>)\n"
     ]
    }
   ],
   "source": [
    "hidden_states = model.encoder.embedding_hidden_mapping_in(emb_output)\n",
    "dist = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "distance_list = []\n",
    "for i in range(n_layers):\n",
    "    input_embedding = hidden_states#.view(-1, 8*768)\n",
    "    layer_out = model.encoder.albert_layer_groups[0](\n",
    "        hidden_states,\n",
    "        extended_attention_mask,\n",
    "        head_mask[0*n_layers:(0+1)*n_layers]\n",
    "    )\n",
    "    hidden_states = layer_out[0]\n",
    "    output_embedding = hidden_states#.view(-1, 8*768)\n",
    "    \n",
    "    distance = torch.dist(input_embedding, output_embedding, p=2)\n",
    "    print(i, hidden_states.shape, input_embedding.shape, output_embedding.shape, distance)\n",
    "    distance_list.append(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0c4f3d0860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(distance_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17683968"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### can ALBERT do NSP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/anything/git/ALBERT/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow as tf\n",
    "import modeling\n",
    "import numpy as np\n",
    "import random\n",
    "import modeling\n",
    "\n",
    "from tokenization import FullTokenizer\n",
    "from load_dataset import create_training_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nm = 'albert_large'\n",
    "model_nm = 'albert_xxlarge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = '/anything/git/ALBERT/models/{}/30k-clean.vocab'.format(model_nm)\n",
    "tokenizer = FullTokenizer(vocab_file=vocab_file)\n",
    "\n",
    "spm_file = '/anything/git/ALBERT/models/{}/30k-clean.model'.format(model_nm)\n",
    "tokenizer = FullTokenizer(vocab_file=None, spm_model_file=spm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = modeling.AlbertConfig.from_json_file('/anything/git/ALBERT/models/{}/albert_config.json'.format(model_nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = config.max_position_embeddings\n",
    "dupe_factor = 40\n",
    "short_seq_prob = 0.1\n",
    "masked_lm_prob = 0.15\n",
    "max_predictions_per_seq = 20\n",
    "rng = random.Random(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOP label should be 0\n",
    "sent_1 = 'How old are you?'\n",
    "sent_2 = 'I am 35 years old'\n",
    "\n",
    "# SOP label should be 1\n",
    "sent_1 = 'How old are you?'\n",
    "sent_2 = 'The Eiffel Tower is in Paris'\n",
    "\n",
    "# SOP label should be 0\n",
    "# sent_1 = 'is Obama the president of the US?'\n",
    "# sent_2 = 'No but he was'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right order\n",
    "tokens_1 = tokenizer.tokenize(sent_1)\n",
    "tokens_2 = tokenizer.tokenize(sent_2)\n",
    "tokens = ['[CLS]'] + tokens_1 + ['[SEP]'] + tokens_2 + ['[SEP]']\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "segment_ids = [0] * (len(tokens_1) + 2) + [1] * (len(tokens_2) + 1)\n",
    "token_type_ids = [1] * len(segment_ids)\n",
    "label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse order\n",
    "tokens_1 = tokenizer.tokenize(sent_1)\n",
    "tokens_2 = tokenizer.tokenize(sent_2)\n",
    "tokens = ['[CLS]'] + tokens_2 + ['[SEP]'] + tokens_1 + ['[SEP]']\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "segment_ids = [0] * (len(tokens_2) + 2) + [1] * (len(tokens_1) + 1)\n",
    "token_type_ids = [1] * len(segment_ids)\n",
    "label = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 13, 1, 3581, 315, 50, 42, 60, 3, 13, 1, 438, 13, 1, 6021, 532, 13, 1, 3581, 106, 25, 19, 13, 1, 14688, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(input_ids)\n",
    "print(segment_ids)\n",
    "print(token_type_ids)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already been converted from strings into ids\n",
    "input_ids = tf.constant([input_ids])\n",
    "segment_ids = tf.constant([segment_ids])\n",
    "token_type_ids = tf.constant([token_type_ids])\n",
    "input_label = tf.constant([label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 26, 64) (1, 64, 26, 64)\n",
      "(1, 64, 26, 64) (1, 64, 26, 64)\n",
      "(1, 64, 26, 64) (1, 64, 26, 64)\n",
      "(1, 64, 26, 64) (1, 64, 26, 64)\n",
      "(1, 64, 26, 64) (1, 64, 26, 64)\n",
      "(1, 64, 26, 64) (1, 64, 26, 64)\n",
      "(1, 64, 26, 64) (1, 64, 26, 64)\n",
      "(1, 64, 26, 64) (1, 64, 26, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0202 13:35:22.587784 139701824845568 deprecation.py:323] From /anything/git/ALBERT/modeling.py:253: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "W0202 13:35:22.589021 139701824845568 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 26, 64) (1, 64, 26, 64)\n",
      "(1, 64, 26, 64) (1, 64, 26, 64)\n",
      "(1, 64, 26, 64) (1, 64, 26, 64)\n",
      "(1, 64, 26, 64) (1, 64, 26, 64)\n"
     ]
    }
   ],
   "source": [
    "model = modeling.AlbertModel(config=config, is_training=False,\n",
    "  input_ids=input_ids, input_mask=token_type_ids, token_type_ids=token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_order_output(albert_config, input_tensor, labels):\n",
    "    with tf.variable_scope(\"cls/seq_relationship\"):\n",
    "        output_weights = tf.get_variable(\n",
    "            \"output_weights\",\n",
    "            shape=[2, albert_config.hidden_size],\n",
    "            initializer=modeling.create_initializer(\n",
    "                albert_config.initializer_range))\n",
    "        output_bias = tf.get_variable(\n",
    "            \"output_bias\", shape=[2], initializer=tf.zeros_initializer())\n",
    "        logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "        labels = tf.reshape(labels, [-1])\n",
    "        one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n",
    "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "        return (loss, per_example_loss, log_probs, output_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sentence_order_loss, sentence_order_example_loss, sentence_order_log_probs, out_weight) = get_sentence_order_output(config, model.get_pooled_output(), input_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30321643 (1, 2) [[-0.30321643 -1.3410888 ]] [[0.73843926 0.26156074]]\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    saver.restore(sess, '/anything/git/ALBERT/models/{}/model.ckpt-best'.format(model_nm))\n",
    "    \n",
    "    sop_loss, sop_prob, ow = sess.run([sentence_order_loss, sentence_order_log_probs, out_weight])\n",
    "    pred = 0 if sop_prob[0][0] > sop_prob[0][1] else 1\n",
    "    print(sop_loss, sop_prob.shape, sop_prob, np.exp(sop_prob))\n",
    "    print(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
